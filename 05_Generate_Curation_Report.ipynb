{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Autonomous Curation Report\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates the complete, end-to-end workflow for generating a comprehensive, human-readable curation report for a scientific dataset. It combines the capabilities of multiple AI agents to transform a poorly documented file into a FAIR-compliant, fully described asset.\n",
    "\n",
    "## The Workflow\n",
    "1.  **Create a realistic test case**: A NetCDF file with minimal metadata and scattered documentation.\n",
    "2.  **Initialize the Multi-Agent System**: Load the `QualityAssessmentAgent`, `DiscoveryAgent`, and `EnrichmentAgent`.\n",
    "3.  **Execute the Autonomous Pipeline**:\n",
    "    a.  The **Quality Agent** validates the file's integrity.\n",
    "    b.  The **Discovery Agent** finds and analyzes companion documents (READMEs, scripts, citations).\n",
    "    c.  The **Enrichment Agent** decodes variables, infers the scientific domain, and adds context.\n",
    "4.  **Generate the Curation Report**: Collate all the information gathered by the agents into a single, detailed markdown report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:34:19.720056Z",
     "iopub.status.busy": "2025-10-17T17:34:19.719758Z",
     "iopub.status.idle": "2025-10-17T17:34:20.968357Z",
     "shell.execute_reply": "2025-10-17T17:34:20.967074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup: Install dependencies and add library to path\n",
    "!pip install -q netCDF4 h5py requests\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'lib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:34:20.973416Z",
     "iopub.status.busy": "2025-10-17T17:34:20.972785Z",
     "iopub.status.idle": "2025-10-17T17:34:21.184457Z",
     "shell.execute_reply": "2025-10-17T17:34:21.183512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all necessary components\n",
    "from ollama_client import OllamaClient\n",
    "from quality_agent import QualityAssessmentAgent\n",
    "from discovery_agent import DiscoveryAgent\n",
    "from enrichment_agent import MetadataEnrichmentAgent\n",
    "from create_demo_dataset import create_mystery_climate_dataset\n",
    "from llm_enricher import DataInspector\n",
    "from companion_extractor import CompanionDocExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Test Dataset\n",
    "We will start by creating the 'mystery climate data' set, which is designed to mimic a real-world HPC output with poor metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:34:21.188170Z",
     "iopub.status.busy": "2025-10-17T17:34:21.187756Z",
     "iopub.status.idle": "2025-10-17T17:34:24.929778Z",
     "shell.execute_reply": "2025-10-17T17:34:24.928248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mystery dataset: mystery_climate_data.nc\n",
      "  (Intentionally minimal metadata for demo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Created NetCDF file: 64170.1 KB\n",
      "  âœ“ Variables: t2m, sst, pr, wspd (cryptic names!)\n",
      "  âœ“ Dimensions: time=365, lat=90, lon=180\n",
      "\n",
      "  Creating companion documentation...\n",
      "    âœ“ README_climate_2023.md\n",
      "    âœ“ process_cmip6_ensemble.py\n",
      "    âœ“ CITATION.bib\n",
      "    âœ“ METADATA.txt\n",
      "\n",
      "  âœ“ Companion documentation created\n",
      "    (README, script, citation, metadata)\n"
     ]
    }
   ],
   "source": [
    "mystery_file = create_mystery_climate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:34:24.934165Z",
     "iopub.status.busy": "2025-10-17T17:34:24.933746Z",
     "iopub.status.idle": "2025-10-17T17:34:24.948354Z",
     "shell.execute_reply": "2025-10-17T17:34:24.947247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Connected to Ollama at http://localhost:11434\n",
      "  Available models: llama3.2:3b\n",
      "  [QualityAgent] Registered tool: check_signature\n",
      "  [QualityAgent] Registered tool: get_file_info\n",
      "  [QualityAgent] Registered tool: inspect_content\n",
      "  [EnrichmentAgent] Registered tool: get_structure\n",
      "  [EnrichmentAgent] Registered tool: domain_knowledge_lookup\n",
      "âœ“ AI Agents initialized and ready.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ollama = OllamaClient()\n",
    "    quality_agent = QualityAssessmentAgent(ollama)\n",
    "    discovery_agent = DiscoveryAgent(ollama)\n",
    "    enrichment_agent = MetadataEnrichmentAgent(ollama)\n",
    "    print(\"âœ“ AI Agents initialized and ready.\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Failed to initialize agents: {e}\")\n",
    "    print(\"  Please ensure Ollama is running ('ollama serve')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Autonomous Curation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:34:24.951629Z",
     "iopub.status.busy": "2025-10-17T17:34:24.951282Z",
     "iopub.status.idle": "2025-10-17T17:36:01.948433Z",
     "shell.execute_reply": "2025-10-17T17:36:01.947985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Curation Pipeline ---\n",
      "\n",
      "1. Quality Assessment...\n",
      "\n",
      "[QualityAgent] Starting analysis...\n",
      "============================================================\n",
      "\n",
      "[QualityAgent] Step 1: Thinking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QualityAgent] Using tool: get_file_info\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'filename': 'mystery_climate_data.nc', 'extension': '.nc', 'size_bytes': 65710183, 'size_mb': 62.67}\n",
      "\n",
      "[QualityAgent] Step 2: Thinking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QualityAgent] Using tool: check_signature\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'expected_type': 'netcdf', 'detected_type': 'netcdf', 'is_valid': True, 'issues': [], 'size': '62.67 MB'}\n",
      "\n",
      "[QualityAgent] Step 3: Thinking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QualityAgent] Using tool: inspect_content\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'appears_text': True, 'appears_html': False, 'sample_text': 'ï¿½HDF\\r\\n\\x1a\\n\\x02\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½gï¿½ï¿½\\x03\\x00\\x00\\x00\\x000\\x00\\x00\\x00\\x00\\x00\\x00\\x00<ï¿½ï¿½]OHDR\\x02\\x0c\n",
      "\n",
      "[QualityAgent] Step 4: Thinking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[QualityAgent] Decision reached!\n",
      "  Decision: ACCEPT\n",
      "  Confidence: 1.00\n",
      "âœ“ Quality Assessment Passed (Confidence: 1.00)\n",
      "\n",
      "2. Companion Discovery...\n",
      "\n",
      "[SimpleDiscoveryAgent] Analyzing: mystery_climate_data.nc\n",
      "============================================================\n",
      "\n",
      "Step 1: Finding candidate documents...\n",
      "Found 7 candidate documents:\n",
      "  - process_cmip6_ensemble.py\n",
      "  - analyze_temperature.py\n",
      "  - process_chlorophyll.py\n",
      "  - README.md\n",
      "  - CITATION.bib\n",
      "  - README_climate_2023.md\n",
      "  - README_chlorophyll_2023.md\n",
      "\n",
      "Evaluating: process_cmip6_ensemble.py\n",
      "  Mentions of 'mystery_climate_data': 8\n",
      "  Preview length: 563 chars\n",
      "  âœ“ RELEVANT (strong signal: 8 mentions)\n",
      "\n",
      "Evaluating: analyze_temperature.py\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 216 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: process_chlorophyll.py\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 403 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: README.md\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 450 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LLM Decision: NOT_RELEVANT (0.80)\n",
      "\n",
      "Evaluating: CITATION.bib\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 667 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: README_climate_2023.md\n",
      "  Mentions of 'mystery_climate_data': 2\n",
      "  Preview length: 609 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LLM Decision: RELEVANT (0.90)\n",
      "\n",
      "Evaluating: README_chlorophyll_2023.md\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 456 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LLM Decision: RELEVANT (1.00)\n",
      "\n",
      "============================================================\n",
      "DISCOVERY SUMMARY\n",
      "============================================================\n",
      "Relevant: 3\n",
      "Uncertain: 0\n",
      "Not relevant: 4\n",
      "âœ“ Companion Discovery Complete (Found 3 relevant documents)\n",
      "\n",
      "3. Metadata Enrichment...\n",
      "\n",
      "[EnrichmentAgent] Starting orchestrated enrichment for: generated/sample_data/mystery_climate_data.nc\n",
      "============================================================\n",
      "[EnrichmentAgent] Step 1: Getting file structure...\n",
      "  > Found 4 variables to enrich: ['t2m', 'sst', 'pr', 'wspd']\n",
      "\n",
      "[EnrichmentAgent] Step 2: Decoding each variable...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Decoded 't2m': temperature at 2 meters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Decoded 'sst': sea surface temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Decoded 'pr': Unknown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ— Failed to decode 'wspd'\n",
      "\n",
      "[EnrichmentAgent] Step 3: Generating final summary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Metadata Enrichment Complete (Confidence: 0.85)\n",
      "\n",
      "--- Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Curation Pipeline ---\\n\")\n",
    "\n",
    "print(\"1. Quality Assessment...\")\n",
    "quality_result = quality_agent.assess_file(str(mystery_file))\n",
    "print(f\"âœ“ Quality Assessment Passed (Confidence: {quality_result.confidence:.2f})\\n\")\n",
    "\n",
    "print(\"2. Companion Discovery...\")\n",
    "discovery_result = discovery_agent.discover_companions(str(mystery_file))\n",
    "print(f\"âœ“ Companion Discovery Complete (Found {len(discovery_result['relevant_companions'])} relevant documents)\\n\")\n",
    "\n",
    "print(\"3. Metadata Enrichment...\")\n",
    "enrichment_result = enrichment_agent.enrich_file(str(mystery_file))\n",
    "print(f\"âœ“ Metadata Enrichment Complete (Confidence: {enrichment_result['confidence']:.2f})\\n\")\n",
    "\n",
    "print(\"--- Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate the Curation Report\n",
    "\n",
    "Now, we will collate all the information gathered by the agents into a single, comprehensive markdown report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T17:36:01.950263Z",
     "iopub.status.busy": "2025-10-17T17:36:01.950111Z",
     "iopub.status.idle": "2025-10-17T17:36:26.643058Z",
     "shell.execute_reply": "2025-10-17T17:36:26.642647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Generating report with LLM... (this may take a moment)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Curation Report\n",
       "## Executive Summary\n",
       "\n",
       "This curation report documents the analysis of a climate data file, \"mystery_climate_data.nc\", collected by a multi-agent system. The file was validated and accepted with a confidence score of 1.00/1.0, indicating its validity and integrity.\n",
       "\n",
       "## Key Findings\n",
       "\n",
       "* The file is a valid scientific data file.\n",
       "* The file has been successfully analyzed for metadata enrichment.\n",
       "* Companion documents include Python scripts (process_cmip6_ensemble.py) and Markdown README files (README_climate_2023.md, README_chlorophyll_2023.md).\n",
       "* The Enrichment Agent identified two variables: \"t2m\" (temperature at 2 meters) and \"sst\" (sea surface temperature).\n",
       "\n",
       "## Dataset Inventory\n",
       "\n",
       "### Primary Data File\n",
       "* **Filename:** mystery_climate_data.nc\n",
       "* **Folder Path:** generated/sample_data\n",
       "* **Size:** 62.67 MB\n",
       "\n",
       "### Variables\n",
       "* `t2m`: \n",
       "  * `full_name`: temperature at 2 meters\n",
       "  * `units`: kelvin\n",
       "  * `domain`: meteorology\n",
       "* `sst`:\n",
       "  * `full_name`: sea surface temperature\n",
       "  * `units`: celsius or kelvin\n",
       "  * `domain`: oceanography\n",
       "\n",
       "## Companion Documents\n",
       "\n",
       "### Python Script\n",
       "* Filename: process_cmip6_ensemble.py\n",
       "\n",
       "### Markdown README Files\n",
       "* `README_climate_2023.md`\n",
       "* `README_chlorophyll_2023.md`\n",
       "\n",
       "## Semantic Enrichment\n",
       "\n",
       "The Enrichment Agent's analysis of the file reveals its scientific context. The variables identified, \"t2m\" and \"sst\", are commonly used in climate research to describe temperature and sea surface conditions. These variables are essential for understanding ocean-atmosphere interactions and global climate patterns. The companion documents provide additional information on the data processing pipeline and research focus areas, further supporting the validity of the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from report_generator import LLMReportGenerator\n",
    "\n",
    "# Initialize the report generator with the ollama client\n",
    "llm_report_generator = LLMReportGenerator(ollama)\n",
    "\n",
    "# Generate the report\n",
    "report_md = llm_report_generator.generate_report(\n",
    "    mystery_file, \n",
    "    quality_result, \n",
    "    discovery_result, \n",
    "    enrichment_result\n",
    ")\n",
    "\n",
    "# Display the report\n",
    "display(Markdown(report_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
