{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Autonomous Curation Report\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates the complete, end-to-end workflow for generating a comprehensive, human-readable curation report for a scientific dataset. It combines the capabilities of multiple AI agents to transform a poorly documented file into a FAIR-compliant, fully described asset.\n",
    "\n",
    "## The Workflow\n",
    "1.  **Create a realistic test case**: A NetCDF file with minimal metadata and scattered documentation.\n",
    "2.  **Initialize the Multi-Agent System**: Load the `QualityAssessmentAgent`, `DiscoveryAgent`, and `EnrichmentAgent`.\n",
    "3.  **Execute the Autonomous Pipeline**:\n",
    "    a.  The **Quality Agent** validates the file's integrity.\n",
    "    b.  The **Discovery Agent** finds and analyzes companion documents (READMEs, scripts, citations).\n",
    "    c.  The **Enrichment Agent** decodes variables, infers the scientific domain, and adds context.\n",
    "4.  **Generate the Curation Report**: Collate all the information gathered by the agents into a single, detailed markdown report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install dependencies and add library to path\n",
    "!pip install -q netCDF4 h5py requests\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'lib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary components\n",
    "from ollama_client import OllamaClient\n",
    "from quality_agent import QualityAssessmentAgent\n",
    "from discovery_agent import DiscoveryAgent\n",
    "from enrichment_agent import MetadataEnrichmentAgent\n",
    "from create_demo_dataset import create_mystery_climate_dataset\n",
    "from llm_enricher import DataInspector\n",
    "from companion_extractor import CompanionDocExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Test Dataset\n",
    "We will start by creating the 'mystery climate data' set, which is designed to mimic a real-world HPC output with poor metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mystery dataset: mystery_climate_data.nc\n",
      "  (Intentionally minimal metadata for demo)\n",
      "  âœ“ Created NetCDF file: 64172.1 KB\n",
      "  âœ“ Variables: t2m, sst, pr, wspd (cryptic names!)\n",
      "  âœ“ Dimensions: time=365, lat=90, lon=180\n",
      "\n",
      "  Creating companion documentation...\n",
      "    âœ“ README_climate_2023.md\n",
      "    âœ“ process_cmip6_ensemble.py\n",
      "    âœ“ CITATION.bib\n",
      "    âœ“ METADATA.txt\n",
      "\n",
      "  âœ“ Companion documentation created\n",
      "    (README, script, citation, metadata)\n"
     ]
    }
   ],
   "source": [
    "mystery_file = create_mystery_climate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Connected to Ollama at http://localhost:11434\n",
      "  Available models: llama3.2:3b\n",
      "  [QualityAgent] Registered tool: check_signature\n",
      "  [QualityAgent] Registered tool: get_file_info\n",
      "  [QualityAgent] Registered tool: inspect_content\n",
      "  [EnrichmentAgent] Registered tool: get_structure\n",
      "  [EnrichmentAgent] Registered tool: domain_knowledge_lookup\n",
      "âœ“ AI Agents initialized and ready.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ollama = OllamaClient()\n",
    "    quality_agent = QualityAssessmentAgent(ollama)\n",
    "    discovery_agent = DiscoveryAgent(ollama)\n",
    "    enrichment_agent = MetadataEnrichmentAgent(ollama)\n",
    "    print(\"âœ“ AI Agents initialized and ready.\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Failed to initialize agents: {e}\")\n",
    "    print(\"  Please ensure Ollama is running ('ollama serve')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Autonomous Curation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Curation Pipeline ---\n",
      "\n",
      "1. Quality Assessment...\n",
      "\n",
      "[QualityAgent] Starting analysis...\n",
      "============================================================\n",
      "\n",
      "[QualityAgent] Step 1: Thinking...\n",
      "[QualityAgent] Using tool: get_file_info\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'filename': 'mystery_climate_data.nc', 'extension': '.nc', 'size_bytes': 65712258, 'size_mb': 62.67}\n",
      "\n",
      "[QualityAgent] Step 2: Thinking...\n",
      "[QualityAgent] Using tool: check_signature\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'expected_type': 'netcdf', 'detected_type': 'netcdf', 'is_valid': True, 'issues': [], 'size': '62.67 MB'}\n",
      "\n",
      "[QualityAgent] Step 3: Thinking...\n",
      "[QualityAgent] Using tool: inspect_content\n",
      "  Parameters: {'filepath': 'generated/sample_data/mystery_climate_data.nc'}\n",
      "  Result: {'appears_text': True, 'appears_html': False, 'sample_text': 'ï¿½HDF\\r\\n\\x1a\\n\\x02\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\\x03\\x00\\x00\\x00\\x000\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x7fivï¿½OHDR\\x02\\\n",
      "\n",
      "[QualityAgent] Step 4: Thinking...\n",
      "\n",
      "[QualityAgent] Decision reached!\n",
      "  Decision: ACCEPT\n",
      "  Confidence: 0.80\n",
      "âœ“ Quality Assessment Passed (Confidence: 0.80)\n",
      "\n",
      "2. Companion Discovery...\n",
      "\n",
      "[SimpleDiscoveryAgent] Analyzing: mystery_climate_data.nc\n",
      "============================================================\n",
      "\n",
      "Step 1: Finding candidate documents...\n",
      "Found 7 candidate documents:\n",
      "  - process_chlorophyll.py\n",
      "  - README.md\n",
      "  - analyze_temperature.py\n",
      "  - README_chlorophyll_2023.md\n",
      "  - CITATION.bib\n",
      "  - process_cmip6_ensemble.py\n",
      "  - README_climate_2023.md\n",
      "\n",
      "Evaluating: process_chlorophyll.py\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 403 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: README.md\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 450 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n",
      "  LLM Decision: NOT_RELEVANT (0.80)\n",
      "\n",
      "Evaluating: analyze_temperature.py\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 216 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: README_chlorophyll_2023.md\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 456 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n",
      "  LLM Decision: RELEVANT (1.00)\n",
      "\n",
      "Evaluating: CITATION.bib\n",
      "  Mentions of 'mystery_climate_data': 0\n",
      "  Preview length: 667 chars\n",
      "  âœ— NOT RELEVANT (no mentions, not a README)\n",
      "\n",
      "Evaluating: process_cmip6_ensemble.py\n",
      "  Mentions of 'mystery_climate_data': 8\n",
      "  Preview length: 563 chars\n",
      "  âœ“ RELEVANT (strong signal: 8 mentions)\n",
      "\n",
      "Evaluating: README_climate_2023.md\n",
      "  Mentions of 'mystery_climate_data': 2\n",
      "  Preview length: 609 chars\n",
      "  ðŸ¤” AMBIGUOUS - asking LLM...\n",
      "  LLM Decision: RELEVANT (0.90)\n",
      "\n",
      "============================================================\n",
      "DISCOVERY SUMMARY\n",
      "============================================================\n",
      "Relevant: 3\n",
      "Uncertain: 0\n",
      "Not relevant: 4\n",
      "âœ“ Companion Discovery Complete (Found 3 relevant documents)\n",
      "\n",
      "3. Metadata Enrichment...\n",
      "\n",
      "[EnrichmentAgent] Starting orchestrated enrichment for: generated/sample_data/mystery_climate_data.nc\n",
      "============================================================\n",
      "[EnrichmentAgent] Step 1: Getting file structure...\n",
      "  > Found 4 variables to enrich: ['t2m', 'sst', 'pr', 'wspd']\n",
      "\n",
      "[EnrichmentAgent] Step 2: Decoding each variable...\n",
      "  âœ“ Decoded 't2m': temperature at 2 meters\n",
      "  âœ“ Decoded 'sst': sea surface temperature\n",
      "  âœ“ Decoded 'pr': Unknown\n",
      "  âœ“ Decoded 'wspd': wind speed\n",
      "\n",
      "[EnrichmentAgent] Step 3: Generating final summary...\n",
      "âœ“ Metadata Enrichment Complete (Confidence: 0.85)\n",
      "\n",
      "--- Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Curation Pipeline ---\\n\")\n",
    "\n",
    "print(\"1. Quality Assessment...\")\n",
    "quality_result = quality_agent.assess_file(str(mystery_file))\n",
    "print(f\"âœ“ Quality Assessment Passed (Confidence: {quality_result.confidence:.2f})\\n\")\n",
    "\n",
    "print(\"2. Companion Discovery...\")\n",
    "discovery_result = discovery_agent.discover_companions(str(mystery_file))\n",
    "print(f\"âœ“ Companion Discovery Complete (Found {len(discovery_result['relevant_companions'])} relevant documents)\\n\")\n",
    "\n",
    "print(\"3. Metadata Enrichment...\")\n",
    "enrichment_result = enrichment_agent.enrich_file(str(mystery_file))\n",
    "print(f\"âœ“ Metadata Enrichment Complete (Confidence: {enrichment_result['confidence']:.2f})\\n\")\n",
    "\n",
    "print(\"--- Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate the Curation Report\n",
    "\n",
    "Now, we will collate all the information gathered by the agents into a single, comprehensive markdown report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Generating report with LLM... (this may take a moment)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Curation Report\n",
       "## Executive Summary\n",
       "\n",
       "This curation report details the analysis of a validated climate data file, mystery_climate_data.nc, located in generated/sample_data folder. The file has been confirmed as valid and uncorrupted with a confidence score of 0.80/1.0.\n",
       "\n",
       "## Key Findings\n",
       "\n",
       "*   The dataset is stored in a NetCDF format file.\n",
       "*   Companion documents, including README_chlorophyll_2023.md, process_cmip6_ensemble.py, and README_climate_2023.md, were discovered, providing additional context to the data.\n",
       "*   The Enrichment Agent successfully decoded variables related to temperature, sea surface temperature, and wind speed.\n",
       "\n",
       "## Dataset Inventory\n",
       "\n",
       "### Primary Data File\n",
       "\n",
       "| **Filename** | **Folder Path** | **Size (MB)** |\n",
       "| --- | --- | --- |\n",
       "| mystery\\_climate\\_data.nc | generated/sample\\_data | 62.67 |\n",
       "\n",
       "### Decoded Variables\n",
       "\n",
       "*   `t2m`: Temperature at 2 meters\n",
       "    *   Units: Kelvin\n",
       "    *   Domain: Meteorology\n",
       "*   `sst`: Sea Surface Temperature\n",
       "    *   Units: Celsius or Kelvin\n",
       "    *   Domain: Oceanography\n",
       "*   `wspd`: Wind Speed\n",
       "    *   Units: M/s\n",
       "    *   Domain: Meteorology\n",
       "\n",
       "## Companion Documents\n",
       "\n",
       "The companion documents provide supplementary information about the dataset. The README_chlorophyll_2023.md file likely contains metadata related to chlorophyll concentrations, while process_cmip6\\_ensemble.py may contain code used for data processing. The README_climate_2023.md file provides an overview of the climate dataset.\n",
       "\n",
       "## Semantic Enrichment\n",
       "\n",
       "The Enrichment Agent identified variables with specific scientific meanings, suggesting that the dataset is related to climate research. The presence of meteorological and oceanographic variables indicates that the dataset may be used for studies involving weather patterns or marine ecosystems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from report_generator import LLMReportGenerator\n",
    "\n",
    "# Initialize the report generator with the ollama client\n",
    "llm_report_generator = LLMReportGenerator(ollama)\n",
    "\n",
    "# Generate the report\n",
    "report_md = llm_report_generator.generate_report(\n",
    "    mystery_file, \n",
    "    quality_result, \n",
    "    discovery_result, \n",
    "    enrichment_result\n",
    ")\n",
    "\n",
    "# Display the report\n",
    "display(Markdown(report_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
