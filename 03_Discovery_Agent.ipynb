{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Companion Documentation\n",
    "\n",
    "Scientific datasets often come with external documentation that provides crucial context:\n",
    "- **README files**: Dataset descriptions, methodology\n",
    "- **Scripts**: Processing code, examples\n",
    "- **Citations**: Papers, DOIs, authors\n",
    "- **Documentation**: User guides, technical notes\n",
    "\n",
    "## Why Companions Matter\n",
    "\n",
    "Academic data frequently has richer metadata in companion files than in the data files themselves. Finding and incorporating this information makes data more FAIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from companion_finder import CompanionDocFinder\n",
    "from companion_extractor import CompanionDocExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Create Sample Companion Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: sample_data/README.md\n"
     ]
    }
   ],
   "source": [
    "# Create sample README\n",
    "readme_file = Path(\"sample_data/README.md\")\n",
    "with open(readme_file, 'w') as f:\n",
    "    f.write(\"\"\"# Ocean Temperature Dataset\n",
    "\n",
    "## Description\n",
    "This dataset contains sea surface temperature measurements from 2020-2023.\n",
    "Data was collected using satellite remote sensing (MODIS Aqua).\n",
    "\n",
    "## Variables\n",
    "- **sst**: Sea surface temperature in Celsius\n",
    "- **lat**: Latitude in degrees north\n",
    "- **lon**: Longitude in degrees east\n",
    "- **time**: Days since 2020-01-01\n",
    "\n",
    "## Contact\n",
    "Institution: Demo University Oceanography Department\n",
    "Email: data@demo.edu\n",
    "Version: 1.0\n",
    "Date: 2023-05-15\n",
    "\n",
    "## License\n",
    "CC BY 4.0\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Created: {readme_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: sample_data/CITATION.txt\n"
     ]
    }
   ],
   "source": [
    "# Create sample citation file\n",
    "citation_file = Path(\"sample_data/CITATION.txt\")\n",
    "with open(citation_file, 'w') as f:\n",
    "    f.write(\"\"\"Citation Information\n",
    "\n",
    "If you use this dataset, please cite:\n",
    "\n",
    "Smith, J., Johnson, A., & Williams, B. (2023). \n",
    "Global Sea Surface Temperature Analysis Using MODIS.\n",
    "Journal of Marine Science, 45(3), 234-256.\n",
    "DOI: 10.1234/jms.2023.001\n",
    "\n",
    "Dataset DOI: 10.5281/zenodo.1234567\n",
    "URL: https://example.com/datasets/sst-2023\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Created: {citation_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: sample_data/process_data.py\n"
     ]
    }
   ],
   "source": [
    "# Create sample processing script\n",
    "script_file = Path(\"sample_data/process_data.py\")\n",
    "with open(script_file, 'w') as f:\n",
    "    f.write('''#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Sea Surface Temperature Data Processing\n",
    "\n",
    "This script processes raw MODIS L2 data and generates\n",
    "daily gridded sea surface temperature files.\n",
    "\n",
    "Author: Jane Smith\n",
    "Date: 2023-05-15\n",
    "Version: 1.0\n",
    "\"\"\"\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "def process_sst_data(input_file, output_file):\n",
    "    \"\"\"Process SST data with quality control\"\"\"\n",
    "    # Quality control: remove values outside physical range\n",
    "    # SST should be between -2°C and 40°C\n",
    "    pass\n",
    "\n",
    "# Processing parameters\n",
    "GRID_RESOLUTION = 0.25  # degrees\n",
    "QC_THRESHOLD = 3  # Quality control threshold\n",
    "''')\n",
    "\n",
    "print(f\"Created: {script_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Find Companions for a Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companion Documents Found:\n",
      "============================================================\n",
      "\n",
      "READMES:\n",
      "  - README.md\n",
      "\n",
      "CITATIONS:\n",
      "  - CITATION.txt\n",
      "\n",
      "SCRIPTS:\n",
      "  - process_data.py\n",
      "\n",
      "Summary: Readmes: 1 file(s); Citations: 1 file(s); Scripts: 1 file(s)\n"
     ]
    }
   ],
   "source": [
    "# Find companions\n",
    "data_file = Path(\"sample_data/ocean_temperature.nc\")\n",
    "finder = CompanionDocFinder()\n",
    "\n",
    "companions = finder.find_companions(data_file)\n",
    "\n",
    "print(\"Companion Documents Found:\")\n",
    "print(\"=\" * 60)\n",
    "for doc_type, files in companions.items():\n",
    "    if files:\n",
    "        print(f\"\\n{doc_type.upper().replace('_', ' ')}:\")\n",
    "        for f in files:\n",
    "            print(f\"  - {f.name}\")\n",
    "\n",
    "# Get summary\n",
    "summary = finder.get_companion_summary(companions)\n",
    "print(f\"\\nSummary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Extract Content from Companions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README Extraction:\n",
      "============================================================\n",
      "File: sample_data/README.md\n",
      "\n",
      "Content Preview (first 300 chars):\n",
      "# Ocean Temperature Dataset\n",
      "\n",
      "## Description\n",
      "This dataset contains sea surface temperature measurements from 2020-2023.\n",
      "Data was collected using satellite remote sensing (MODIS Aqua).\n",
      "\n",
      "## Variables\n",
      "- **sst**: Sea surface temperature in Celsius\n",
      "- **lat**: Latitude in degrees north\n",
      "- **lon**: Longitude...\n"
     ]
    }
   ],
   "source": [
    "extractor = CompanionDocExtractor()\n",
    "\n",
    "# Extract README\n",
    "if companions['readmes']:\n",
    "    readme_data = extractor.extract_readme(companions['readmes'][0])\n",
    "    \n",
    "    print(\"README Extraction:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"File: {readme_data['filepath']}\")\n",
    "    print(f\"\\nContent Preview (first 300 chars):\")\n",
    "    print(readme_data['content'][:300] + \"...\")\n",
    "    \n",
    "    if readme_data.get('metadata'):\n",
    "        print(f\"\\nExtracted Metadata:\")\n",
    "        for key, value in readme_data['metadata'].items():\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Citation Extraction:\n",
      "============================================================\n",
      "File: CITATION.txt\n",
      "DOI: 10.1234/jms.2023.001\n",
      "Year: 2023\n",
      "URL: https://example.com/datasets/sst-2023\n"
     ]
    }
   ],
   "source": [
    "# Extract citation info\n",
    "if companions['citations']:\n",
    "    citation_data = extractor.extract_citation_info(companions['citations'][0])\n",
    "    \n",
    "    print(\"\\nCitation Extraction:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"File: {Path(citation_data['filepath']).name}\")\n",
    "    \n",
    "    if citation_data.get('doi'):\n",
    "        print(f\"DOI: {citation_data['doi']}\")\n",
    "    \n",
    "    if citation_data.get('authors'):\n",
    "        print(f\"Authors: {', '.join(citation_data['authors'])}\")\n",
    "    \n",
    "    if citation_data.get('year'):\n",
    "        print(f\"Year: {citation_data['year']}\")\n",
    "    \n",
    "    if citation_data.get('url'):\n",
    "        print(f\"URL: {citation_data['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script Extraction:\n",
      "============================================================\n",
      "File: process_data.py\n",
      "Language: py\n",
      "\n",
      "Docstring:\n",
      "Sea Surface Temperature Data Processing\n",
      "\n",
      "This script processes raw MODIS L2 data and generates\n",
      "daily gridded sea surface temperature files.\n",
      "\n",
      "Author: Jane Smith\n",
      "Date: 2023-05-15\n",
      "Version: 1.0...\n",
      "\n",
      "Extracted Metadata:\n",
      "  author: Jane Smith\n",
      "  date: 2023-05-15\n",
      "  version: 1.0\n",
      "\n",
      "Imports: netCDF4, numpy\n"
     ]
    }
   ],
   "source": [
    "# Extract script metadata\n",
    "if companions['scripts']:\n",
    "    script_data = extractor.extract_script_metadata(companions['scripts'][0])\n",
    "    \n",
    "    print(\"\\nScript Extraction:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"File: {Path(script_data['filepath']).name}\")\n",
    "    print(f\"Language: {script_data['language']}\")\n",
    "    \n",
    "    if script_data.get('docstring'):\n",
    "        print(f\"\\nDocstring:\")\n",
    "        print(script_data['docstring'][:200] + \"...\")\n",
    "    \n",
    "    if script_data.get('metadata'):\n",
    "        print(f\"\\nExtracted Metadata:\")\n",
    "        for key, value in script_data['metadata'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    if script_data.get('imports'):\n",
    "        print(f\"\\nImports: {', '.join(script_data['imports'][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Create Searchable Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searchable Summary from Companions:\n",
      "============================================================\n",
      "# Ocean Temperature Dataset ## Description This dataset contains sea surface temperature measurements from 2020-2023. Data was collected using satellite remote sensing (MODIS Aqua). ## Variables - **sst**: Sea surface temperature in Celsius - **lat**: Latitude in degrees north - **lon**: Longitude in degrees east - **time**: Days since 2020-01-01 ## Contact Institution: Demo University Oceanography Department Email: data@demo.edu Version: 1.0 Date: 2023-05-15 ## License CC BY 4.0 DOI: 10.1234/jm...\n",
      "\n",
      "============================================================\n",
      "Total length: 857 characters\n",
      "\n",
      "This text will be combined with data file metadata for search.\n"
     ]
    }
   ],
   "source": [
    "# Collect all companion data\n",
    "companion_data = []\n",
    "\n",
    "for readme in companions['readmes']:\n",
    "    companion_data.append(extractor.extract_readme(readme))\n",
    "\n",
    "for citation in companions['citations']:\n",
    "    companion_data.append(extractor.extract_citation_info(citation))\n",
    "\n",
    "for script in companions['scripts']:\n",
    "    companion_data.append(extractor.extract_script_metadata(script))\n",
    "\n",
    "# Create searchable summary\n",
    "summary_text = extractor.create_companion_summary(companion_data)\n",
    "\n",
    "print(\"Searchable Summary from Companions:\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_text[:500] + \"...\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Total length: {len(summary_text)} characters\")\n",
    "print(\"\\nThis text will be combined with data file metadata for search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Directory-Wide Companion Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Companions in Directory:\n",
      "============================================================\n",
      "\n",
      "Readmes: 1\n",
      "  - README.md\n",
      "\n",
      "Citations: 1\n",
      "  - CITATION.txt\n",
      "\n",
      "Documentation: 0\n",
      "\n",
      "Scripts: 1\n",
      "  - process_data.py\n"
     ]
    }
   ],
   "source": [
    "# Find all companions in directory\n",
    "dir_companions = finder.find_directory_companions(Path(\"sample_data\"))\n",
    "\n",
    "print(\"All Companions in Directory:\")\n",
    "print(\"=\" * 60)\n",
    "for doc_type, files in dir_companions.items():\n",
    "    print(f\"\\n{doc_type.replace('_', ' ').title()}: {len(files)}\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact on FAIR Principles\n",
    "\n",
    "Incorporating companion documents improves:\n",
    "\n",
    "1. **Findability**: More keywords and context for search\n",
    "2. **Accessibility**: Contact information, URLs, DOIs\n",
    "3. **Interoperability**: Processing examples, format details\n",
    "4. **Reusability**: Citations, methodology, license info\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "When creating datasets:\n",
    "- Include a README.md with dataset description\n",
    "- Add CITATION.txt with proper attribution\n",
    "- Provide example processing scripts\n",
    "- Document data quality and methodology\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Notebook 04**: Generate embeddings and build search index\n",
    "- **Notebook 05**: See companions integrated into batch indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
